{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5b88a3-9c79-47b5-b9d1-19f2d4419641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 리뷰 수(가게명 있는 것만): 66399\n",
      "20글자 초과만 남김: 37593 삭제: 28806\n",
      "저장 완료: data/중랑구_store_cards(600,100).jsonl\n",
      "가게 카드 수: 1558\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "df = pd.read_csv(\"data/중랑구최종데이터.csv\")\n",
    "df.head()\n",
    "\n",
    "# 결측 처리(NaN 빈 문자열로 변경 + 전부 문자열로 통일 + 공백 제거)\n",
    "df[\"name\"] = df[\"name\"].fillna(\"\").astype(str).str.strip()\n",
    "df[\"review_text\"] = df[\"review_text\"].fillna(\"\").astype(str)\n",
    "\n",
    "# 가게명 없는 건 카드 만들기 불가 → 제거\n",
    "df = df[df[\"name\"] != \"\"].copy()\n",
    "\n",
    "# 공백 제거 후 글자수 계산\n",
    "def review_len_no_space(text):\n",
    "    return len(re.sub(r\"\\s+\", \"\", text))\n",
    "\n",
    "df[\"review_len\"] = df[\"review_text\"].apply(review_len_no_space)\n",
    "\n",
    "# 전체 리뷰\n",
    "before = len(df)\n",
    "df = df[df[\"review_len\"] > 20].copy()\n",
    "# 20글자 초과 리뷰\n",
    "after = len(df)\n",
    "\n",
    "print(\"원본 리뷰 수(가게명 있는 것만):\", before)\n",
    "print(\"20글자 초과만 남김:\", after, \"삭제:\", before-after)\n",
    "\n",
    "# address2(지번) 없으면 \"\" 처리\n",
    "if \"address2\" not in df.columns:\n",
    "    df[\"address2\"] = \"\"\n",
    "\n",
    "df[\"address2\"] = df[\"address2\"].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "# 가게 구분 키(지점 섞임 방지: name + address2)\n",
    "df[\"store_key\"] = df[\"name\"] + \" | \" + df[\"address2\"]\n",
    "\n",
    "# 가게별 리뷰 합치기\n",
    "store_df = df.groupby(\"store_key\").agg(\n",
    "    name=(\"name\", \"first\"),\n",
    "    category=(\"category\", \"first\"),\n",
    "    address1=(\"address1\", \"first\"),\n",
    "    address2=(\"address2\", \"first\"),\n",
    "    review_count=(\"review_text\", \"count\"),\n",
    "    merged_review=(\"review_text\", lambda x: \"\\n\".join([\"- \" + str(t).strip() for t in x if str(t).strip()]))\n",
    ").reset_index()\n",
    "\n",
    "store_df.head()\n",
    "\n",
    "# 청킹(문자 길이 기준)\n",
    "def chunk_text(text, chunk_size=800, overlap=120):\n",
    "    # text: 쪼갤 전체 문자열(가게 리뷰를 전부 합친 merged_review 같은 것)\n",
    "    # chunk_size: 한 청크(조각)에 들어갈 최대 글자 수\n",
    "    # overlap: 청크끼리 서로 겹치게(중복되게) 넣을 글자 수\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        # 청크 크기 만큼 자르기 : end\n",
    "        end = start + chunk_size\n",
    "        # 슬라이싱 하여 chunks부분에 추가\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap  \n",
    "        if start < 0:\n",
    "            start = 0\n",
    "    return chunks\n",
    "\n",
    "# 단어 토큰화\n",
    "token_pat = re.compile(r\"[가-힣A-Za-z0-9]+\")\n",
    "\n",
    "# 불용어(원하면 계속 추가)\n",
    "stopwords = set([\"그리고\",\"그러나\",\"하지만\",\"그래서\",\"또한\",\"그냥\",\"너무\",\"정말\",\"진짜\",\n",
    "                 \"조금\",\"완전\",\"매우\",\"아주\",\"있다\",\"없다\",\"하다\",\"되다\",\"같다\",\"정도\",\"때문\"])\n",
    "\n",
    "def get_top_keywords(text, top_k=20):\n",
    "    # 형태소 분석 → 불필요 품사 제거 → 1글자 제거 → dict로 카운트\n",
    "\n",
    "    # 1) 형태소 분석 + 원형화(stem=True)\n",
    "    #    - Noun(명사), Adjective(형용사)만 남기면 조사/어미가 확 줄어듦\n",
    "    tokens = [w for w, pos in okt.pos(text, stem=True) if pos in (\"Noun\", \"Adjective\")]\n",
    "\n",
    "    # 2) 1글자 제거 + 숫자만 제거 + 불용어 제거\n",
    "    tokens = [t for t in tokens if len(t) >= 2 and (not t.isdigit()) and (t not in stopwords)]\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "\n",
    "    # 3) dict로 빈도 카운트 \n",
    "    word_count = {}\n",
    "    for token in tokens:\n",
    "        word_count[token] = word_count.get(token, 0) + 1\n",
    "\n",
    "    # 4) 상위 top_k 정렬해서 반환\n",
    "    top_items = sorted(word_count.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return [[w, int(c)] for w, c in top_items]\n",
    "\n",
    "out_path = \"data/중랑구_store_cards(600,100).jsonl\"\n",
    "\n",
    "records = []\n",
    "\n",
    "for i in range(len(store_df)):\n",
    "    row = store_df.iloc[i]\n",
    "    merged = row[\"merged_review\"]\n",
    "\n",
    "    # 청킹\n",
    "    chunks = chunk_text(merged, chunk_size=600, overlap=100)\n",
    "\n",
    "    # 전체 키워드 Top20\n",
    "    top_keywords_store = get_top_keywords(merged, top_k=20)\n",
    "\n",
    "    # 청크별 키워드 Top10\n",
    "    chunk_list = []\n",
    "    for idx, ch in enumerate(chunks):\n",
    "        chunk_list.append({\n",
    "            \"chunk_id\": idx,\n",
    "            \"text\": ch,\n",
    "            \"top_keywords\": get_top_keywords(ch, top_k=10)\n",
    "        })\n",
    "\n",
    "    rec = {\n",
    "        \"store_key\": row[\"store_key\"],\n",
    "        \"name\": row[\"name\"],\n",
    "        \"category\": row[\"category\"],\n",
    "        \"address1\": row[\"address1\"],\n",
    "        \"address2\": row[\"address2\"],\n",
    "        \"review_count\": int(row[\"review_count\"]),\n",
    "        \"top_keywords\": top_keywords_store,\n",
    "        \"merged_review\": merged,\n",
    "        \"chunks\": chunk_list\n",
    "    }\n",
    "\n",
    "    records.append(rec)\n",
    "\n",
    "# JSONL 저장\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in records:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"저장 완료:\", out_path)\n",
    "print(\"가게 카드 수:\", len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba6d48-1ab9-4f01-8988-50aa77692be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
